---
title: "site_specific_confidence_interval"
author: "GabiK"
date: '2022-03-31'
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r libraries, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# required packages
library(adagio)
library(tidyverse)
library(lubridate)
library(ggpubr)
# required scripts
source("./TimeFrame5.R")
source("./smallestsubwithsum.R")
```

```{r functions}
#use site-specific mean net error and SD based on IR video data
estimate_site = function(LB,passes,max,mean_pass,SD,mean_net_error,blocked_hours=0,fp_missed,innerloop_missed){
    chunk=floor(passes/100)
    missedpasses=fp_missed*chunk + 1*chunk + innerloop_missed*chunk + blocked_hours*mean_pass
    missed_chunks=round(missedpasses/100,1)
    real_chunks=floor(chunk+missed_chunks)
    se=SD/sqrt(real_chunks)
    ratio=round(passes/max,2)
    print(paste0("Total passes/population size estimate = ",ratio),quote = FALSE)
    lcl = round((mean_net_error - qt(1 - (0.05 / 2), real_chunks - 1) * se) * real_chunks,0)
    print(paste0("LCL:",round(lcl,2)),quote=FALSE)
    ucl = round((mean_net_error + qt(1 - (0.05 / 2), real_chunks - 1) * se) * real_chunks,0)
    print(paste0("UCL:",round(ucl,2)),quote=FALSE)
    print(paste0("Population size estimate: ",max," (",max+lcl,"-",max+ucl,")") ,quote = FALSE)
    return(c(max,max+lcl,max+ucl))
}

# mean net error set to ±1, SD extrapolated based on regression
estimate_with_SD = function(passes,max,mean_pass,blocked_hours=0){
    chunk=floor(passes/100)
    #Regression (ratio of total passes:population size estimate to missed passes)
    #estimated regression slope = 0.83
    regression_estimate_SD=0.83
    missedpasses=0.2*chunk + 1*chunk + chunk*regression_estimate_SD*(passes/max) + blocked_hours*mean_pass
    missed_chunks=round(missedpasses/100,1)
    real_chunks=floor(chunk+missed_chunks)
    print(paste0("Original chunks: ",chunk),quote = FALSE)
    print(paste0("Real chunks: ",real_chunks),quote = FALSE)
    ratio=round(passes/max,2)
    print(paste0("Total passes/population size estimate = ",ratio),quote = FALSE)
    #Regression (ratio of total passes:population size estimate to SD)
    #estimated regression slope = 0.22
    #SD=1 accounts for error based on consecutive LBs in Eldena, Gaussian error prop
    regression_estimate=0.22
    SD=round(sqrt((1*1)+(ratio*regression_estimate)*(ratio*regression_estimate)),2) 
    print(paste0("SD extrapolated = ",SD),quote = FALSE)
    se=SD/sqrt(real_chunks)
    mean_net_error=0
    print("Mean net error set to ±1 ",quote = FALSE)
    lcl = round(((mean_net_error-1) - qt(1 - (0.05 / 2), real_chunks - 1) * se) * real_chunks,0)
    ucl = round(((mean_net_error+1) + qt(1 - (0.05 / 2), real_chunks - 1) * se) * real_chunks,0)
    print(paste0("Population size estimate: ",max," (",max+lcl,"-",max+ucl,")") ,quote = FALSE)
    return(c(max,max+lcl,max+ucl))
}
```

## ESTIMATING POPULATION SIZE FOR SITES WITH IR VIDEO DATA

```{r loop}
Sites=c("Anklam","Peenemuende","Friedland","Demmin","Eldena","Eldena_L8","Eldena_L16")

blocked_hours_df=data.frame(Site=0,blocked_hours=0)
confidence_intervals=data.frame(Site=0, year=0, LB=0 , lcl=0, ucl=0)
confidence_intervals_adj=data.frame(Site=0, year=0, LB=0 , lcl_adj=0, ucl_adj=0)

possYear=2021
for (Site in Sites){#loop through each site
  blocked_periods=data.frame(blocked_minute=0)
      #calculate blocked periods
      dat=read.csv(paste0("./data/curtain_data/",Site,".txt"), sep=";")
      status=dat %>% 
        dplyr::select(Datum,Uhrzeit,Event) %>% 
        filter(grepl('Status', Event)) %>% 
        mutate(datetime=paste(as.character(Datum),as.character(Uhrzeit)))
      status$datetime2=as.POSIXct(status$datetime,format="%d.%m.%Y %H:%M:%S", tz="GMT")
      status$Datum=as.Date(status$Datum, tryFormats = c("%d.%m.%Y"))
      
      emergence_dates=read.csv("./emergence/LB_estimates_dates.csv")
      
      #emergence dates and population size estimates
      emergence_start=emergence_dates$start[emergence_dates$Site==Site & emergence_dates$year==possYear]
      emergence_start
      emergence_end=emergence_dates$end[emergence_dates$Site==Site & emergence_dates$year==possYear]
      emergence_end
      netvalue=emergence_dates$estimate[emergence_dates$Site==Site & emergence_dates$year==possYear]
      netvalue
      if (Site=="Eldena_L8" | Site=="Eldena"){
        #EMERGENCE PHASE
        stat_filt=
          status %>% 
          filter(as.Date(status$Datum)>as.Date(emergence_start) & 
                   as.Date(status$Datum)<as.Date(emergence_end)) %>% 
          filter(grepl("LS3",Event))
        
        nrow(stat_filt)
        zeros=which(stat_filt$Event=="LS3 EStatus 0") #indices of Status 0
        threshold=1 #minutes, set time between Status 1/2/3 (that is after a 0) and next 0
        
        for (i in zeros[-length(zeros)]) {    
          if (stat_filt$Event[i+1]!="LS3 EStatus 0") {  # check if next event is Status 1/2/3 
            #print(i)
            first_datetime=stat_filt$datetime2[i+1] # date time of the Status 1/2/3 event
            which(zeros==i) #index of current 0
            which(zeros==i)+ 1#index of next 0
            zeros[which(zeros==i)+ 1] #row of next 0
            last_datetime=stat_filt$datetime2[zeros[which(zeros==i)+ 1]] #date time of next 0
            time_diff=difftime(last_datetime,first_datetime, units="mins")
            if (as.numeric(time_diff) > threshold) {
              #print(paste("LB blocked from",first_datetime,"to",last_datetime))
              minutes=seq(first_datetime,last_datetime, by='min')
              minutes=format(minutes,"%Y-%m-%d %H:%M:%S")
              for (m in 1:length(minutes)){
                if(format(strptime(minutes[m],"%Y-%m-%d %H:%M:%S"),'%H:%M:%S')<"09:00:00" |
                   format(strptime(minutes[m],"%Y-%m-%d %H:%M:%S"),'%H:%M:%S')>"15:00:00"){
                  row=c(as.character(minutes[m]))
                  blocked_periods=rbind(blocked_periods,as.character(row))  
                }
                
                
              }
              
            }
          }
        } 
      } else {
        #EMERGENCE PHASE
        stat_filt=
          status %>% 
          filter(as.Date(status$Datum)>as.Date(emergence_start) & 
                   as.Date(status$Datum)<as.Date(emergence_end)) %>% 
          filter(grepl("LS1",Event))
        
        nrow(stat_filt)
        zeros=which(stat_filt$Event=="LS1 EStatus 0") #indices of Status 0
        threshold=1 #minutes, set time between Status 1/2/3 (that is after a 0) and next 0
        
        for (i in zeros[-length(zeros)]) {    
          if (stat_filt$Event[i+1]!="LS1 EStatus 0") {  # check if next event is Status 1/2/3 
            #print(i)
            first_datetime=stat_filt$datetime2[i+1] # date time of the Status 1/2/3 event
            which(zeros==i) #index of current 0
            which(zeros==i)+ 1#index of next 0
            zeros[which(zeros==i)+ 1] #row of next 0
            last_datetime=stat_filt$datetime2[zeros[which(zeros==i)+ 1]] #date time of next 0
            time_diff=difftime(last_datetime,first_datetime, units="mins")
            if (as.numeric(time_diff) > threshold) {
              #print(paste("LB blocked from",first_datetime,"to",last_datetime))
              minutes=seq(first_datetime,last_datetime, by='min')
              minutes=format(minutes,"%Y-%m-%d %H:%M:%S")
              for (m in 1:length(minutes)){
                if(format(strptime(minutes[m],"%Y-%m-%d %H:%M:%S"),'%H:%M:%S')<"09:00:00" |
                   format(strptime(minutes[m],"%Y-%m-%d %H:%M:%S"),'%H:%M:%S')>"15:00:00"){
                  row=c(as.character(minutes[m]))
                  blocked_periods=rbind(blocked_periods,as.character(row))  
                }
                
                
              }
              
            }
          }
        } 
        
        
      }
      
      blocked_periods=blocked_periods[-1,]
      length(unique(blocked_periods))
      round(length(unique(blocked_periods))/60,0)
      row2=c(Site, round(length(unique(blocked_periods))/60,0))
      blocked_hours_df=rbind(blocked_hours_df,row2)
      
      #calculate mean passes and net passes/hour
      if (Site=="Eldena_L8" ){
        Dat=read.csv(paste0("./data/pseudo_spring_emergence/Eldena_pseudo.csv"))
        Dat=subset(Dat,Dat$LS=="C")
        head(Dat)
        
      } else if (Site=="Eldena_L16") {
        Dat=read.csv(paste0("./data/pseudo_spring_emergence/Eldena_pseudo.csv"))
        Dat=subset(Dat,Dat$LS=="A")
        head(Dat)
      } else if (Site=="Eldena") {
        Dat=read.csv(paste0("./data/pseudo_spring_emergence/Eldena_pseudo.csv"))
        Dat=subset(Dat,Dat$LS!="A")
        head(Dat)
      } else {
        Dat=read.csv(paste0("./data/pseudo_spring_emergence/",Site,"_pseudo.csv"))
        head(Dat)
      }
      
      merged_spring=Dat %>% 
        filter(as.Date(Dat$pseudodate)>as.Date(emergence_start) & 
                 as.Date(Dat$pseudodate)<as.Date(emergence_end)) %>% 
        mutate(Uhrzeit = as.POSIXct(Uhrzeit, format = "%H:%M:%S"),
                hour = strftime(Uhrzeit, format="%H")) 
  
      
      merged_spring$hour=as.numeric(merged_spring$hour)
      merged_spring$pseudodate=ymd(merged_spring$pseudodate)
      
     
      #average passes and net per hour
      passes_hour=merged_spring %>%
        filter(hour>15 | hour<9) %>% #daytime filter
        group_by(pseudodate,hour) %>% 
        summarise(n=sum(abs(EventC)),
                  net=sum(EventC)) %>%
        ungroup() %>% 
        complete(pseudodate=seq(min(pseudodate),max(pseudodate),by='day'), 
                                     fill = list(n= 0, hour=0, net=0)) %>%
        group_by(pseudodate) %>% 
        complete(hour=c(seq(15,23),seq(0,9)),
                 fill = list(n= 0, net=0)) 
      
      total_pass=sum(passes_hour$n)
      
      print(paste0("Total passes during emergence: ",total_pass),quote = FALSE)
      mean_pass=round(mean(passes_hour$n),2)
      print(paste0("Average passes per hour during emergence: ",mean_pass),quote = FALSE)
      net_pass=round(mean(passes_hour$net),2)
      print(paste0("Average net per hour during emergence: ",net_pass),quote = FALSE)
      
      #calculate confidence interval for NET passes/hour
      sd=sd(passes_hour$net)
      n_chunk=length(passes_hour$net)
      se=sd / sqrt(n_chunk)
      ucl = net_pass - qt(1 - (0.05 / 2), n_chunk - 1) * se
      ucl
      print(paste0("Average NET per hour UCL: ",round(ucl,2)),quote = FALSE)
      
      lcl = net_pass + qt(1 - (0.05 / 2), n_chunk - 1) * se
      lcl
      print(paste0("Average NET per hour LCL: ",round(lcl,2)),quote = FALSE)
      
      #Site-specific blocked hours   
      blocked_hours=as.numeric(blocked_hours_df$blocked_hours[blocked_hours_df$Site==Site])
      print(paste0("Blocked hours: ",blocked_hours," hrs"),quote = FALSE)
      
      correction_lower=round(blocked_hours*lcl,0)
      print(paste("Correct lcl due to blocked hours:",correction_lower),quote = FALSE)
      correction_upper=round(blocked_hours*ucl,0)
      print(paste("Correct ucl due to blocked hours:",correction_upper),quote = FALSE)
      
      SDs=read.csv("./accuracy/output/spring_error_summary.csv")
      if(Site=="Anklam"){
        LB_model="L4"
        SD_flutter=1
        SD_site=SDs$sd_error[SDs$Site==Site]
        SD=sqrt(SD_flutter*SD_flutter+SD_site*SD_site)
        mean_net_error=SDs$mean_error[SDs$Site==Site]+(-0.4)
        fp_missed=0.06
        innerloop_missed=1
      }else if (Site=="Peenemuende"){
        LB_model="L4"
        SD_flutter=1
        SD_site=SDs$sd_error[SDs$Site==Site]
        SD=sqrt(SD_flutter*SD_flutter+SD_site*SD_site)
        mean_net_error=SDs$mean_error[SDs$Site==Site]+(-0.4)
        fp_missed=0.21
        innerloop_missed=13
      } else if (Site=="Friedland"){
        LB_model="L16"
        SD_flutter=1
        SD_site=SDs$sd_error[SDs$Site==Site]
        SD=sqrt(SD_flutter*SD_flutter+SD_site*SD_site)
        mean_net_error=SDs$mean_error[SDs$Site==Site]+(-0.4)
        fp_missed=0
        innerloop_missed=15
      } else if (Site=="Demmin"){
        LB_model="L16k"
        SD_flutter=1
        SD_site=SDs$sd_error[SDs$Site==Site]
        SD=sqrt(SD_flutter*SD_flutter+SD_site*SD_site)
        mean_net_error=SDs$mean_error[SDs$Site==Site]+(-0.4)
        fp_missed=0
        innerloop_missed=1
      } else if (Site=="Eldena_L8"){
        LB_model="L16k"
        SD_flutter=1
        SD_site=SDs$sd_error[SDs$Site==Site]
        SD=sqrt(SD_flutter*SD_flutter+SD_site*SD_site)
        mean_net_error=SDs$mean_error[SDs$Site==Site]+(-0.4)
        fp_missed=0
        innerloop_missed=0
      }else if (Site=="Eldena_L16"){
        LB_model="L16"
        SD_flutter=1
        SD_site=SDs$sd_error[SDs$Site==Site]
        SD=sqrt(SD_flutter*SD_flutter+SD_site*SD_site)
        mean_net_error=SDs$mean_error[SDs$Site==Site]+(-0.4)
        fp_missed=0.05
        innerloop_missed=12
      } else if (Site=="Eldena"){
        LB_model="L16k"
        SD_flutter=1
        SD_site=SDs$sd_error[SDs$Site=="Eldena_L8"]
        SD=sqrt(SD_flutter*SD_flutter+SD_site*SD_site)
        mean_net_error=SDs$mean_error[SDs$Site=="Eldena_L8"]+(-0.4)
        fp_missed=0
        innerloop_missed=0
      }
      
      print(paste0("SD = ",round(SD,2)),quote = FALSE)
      print(paste0("Mean net error = ",round(mean_net_error,2)),quote = FALSE)
      print(Site)
      
      a=estimate_site(LB_model,total_pass, netvalue, mean_pass, SD,mean_net_error, 
                 blocked_hours, fp_missed, innerloop_missed)
      print(paste("estimate:",a[1],", lcl:",a[2],", ucl:",a[3])) 
      
      row=c(Site,possYear,a[1],a[2]+abs(correction_lower),a[3]+abs(correction_upper))
      
      
      #print(row)
      print("------------------------------------")
      confidence_intervals=rbind(confidence_intervals,row)
      
      
      b=estimate_with_SD(total_pass, netvalue, mean_pass,blocked_hours)
      row2=c(Site,possYear,b[1],b[2]+abs(correction_lower),b[3]+abs(correction_upper))
      #print(row2)
      print("------------------------------------")
      confidence_intervals_adj=rbind(confidence_intervals_adj,row2)
      #################################v

      
  #} #end of loop per year
  
} 
```

```{r save_tables}
write.csv(blocked_hours_df[-1,], 
          paste0("./accuracy/output/blocked_hours_IR_sites.csv"),
          row.names = F)

write.csv(confidence_intervals[-1,], 
          paste0("./accuracy/output/site_specific_CI_IRsites.csv"),
          row.names = F)

write.csv(confidence_intervals_adj[-1,], 
          paste0("./accuracy/output/extrapolated_CI_IRsites.csv"),
          row.names = F)
```

```{r regression_missed_passes}
#Ratio of total passes:population size estimate; missed passes (due to innerloops) based on the video data
df=read.csv("./accuracy/output/spring_error_summary.csv")

df2=read.csv("./emergence/LB_estimates_dates.csv")
df2=df2%>%
  mutate(ratio=total_passes/estimate) %>% 
  dplyr::select(Site,ratio,start,end)

Sites=unique(df$Site)
missed_pass_df=data.frame(Site=0,missed_pass=0)
for (Site in Sites){
  df=read.csv(paste0("./data/accuracy_data/",Site,"_spring_pseudo.csv"))
  head(df)
  df$pseudodate=as.Date(df$pseudodate, tryFormats = ("%d/%m/%Y"))
  emergencestart=df2$start[df2$Site==Site]
  emergenceend=df2$end[df2$Site==Site]
  
  filtdf=df %>% 
    filter(pseudodate>=emergencestart & pseudodate<=emergenceend) %>% 
    filter(EventC!=0)
  nrow(filtdf)
  missed_passes=df %>% 
    filter(pseudodate>=emergencestart & pseudodate<=emergenceend) %>% 
    filter(VideoC!=0 & EventC==0 & Innerloop==1) 
  missed_pass_ratio=round(nrow(missed_passes)*100/nrow(filtdf),2)
  row=c(Site,missed_pass_ratio)
  missed_pass_df=rbind(missed_pass_df,row)
}

dat=left_join(missed_pass_df[-1,],df2) %>% 
  dplyr::select(Site,ratio,missed_pass)
str(dat)
dat$missed_pass=as.numeric(dat$missed_pass)

summary(lm(missed_pass~0+ratio, data=dat))

reg_pass=
  ggscatter(dat, x = "ratio", y = "missed_pass", add = "reg.line",conf.int = TRUE, 
          add.params = list(color = "black", fill = "lightgray"),) +
  labs(y="missed passes",
       x="total passes/population size estimate")+
  annotate("text", x =9, y=21, label=c(expression(paste("R"^"2","= 0.79, p = 0.005"))))+
  annotate("text", x =9, y=18, label=c(expression(paste("Est = 0.83"))))
#0.83 missed pass per 100 pass ("chunk")
#estimate total missed passes: chunk*0.83*(total passes/population size estimate)
reg_pass

ggsave(paste0("./accuracy/output/regression_missedpass.png"),
       width =12, height =12, dpi = 800, units = "cm", device='png')
```

```{r regression_SD}
#Ratio of total passes:population size estimate; SD (mainly due to innerloops) based on the video data
df=read.csv("./accuracy/output/spring_error_summary.csv")
df2=read.csv("./emergence/LB_estimates_dates.csv")
dat=left_join(df,df2, by="Site") %>%
  mutate(ratio=total_passes/estimate) %>% 
  dplyr::select(Site,ratio,sd_error)

intercept <- 1 #force intercept to 0
mod=summary(lm(I(sd_error - intercept) ~ 0 + ratio, data=dat))
#increase SD with 0.23 for every increase in the ratio
#calculate final SD: 1 + ratio*0.23
round(mod$r.squared,2)
round(mod$coefficients[4],3)
round(mod$coefficients[1],2)
reg_SD=ggscatter(dat, x = "ratio", y = "sd_error", add = "reg.line",conf.int = TRUE, 
          add.params = list(color = "black", fill = "lightgray"),) +
  labs(y="standard deviation",
       x="total passes/population size estimate")+
  annotate("text", x =9, y=7.5, 
           label=c(expression(paste("R"^"2","= 0.78, p = 0.009"))))+
  annotate("text", x =9, y=6.5, 
           label=c(expression(paste("Est = 0.22"))))
reg_SD

ggsave(paste0("./accuracy/output/regression_SD.png"),
       width =12, height =12, dpi = 800, units = "cm", device='png')
```

```{r regression_plots}
ggarrange(reg_SD,reg_pass,nrow=1)
ggsave("./accuracy/output/regression_SD_passes.png",
           width = 28, height = 10, dpi = 800, units = "cm", device='png' )
```

#  POPULATION SIZE FOR SITES based on IR VIDEO DATA

```{r loop}
#file with site names and years
Sites=c("Anklam","Peenemuende","Friedland","Demmin","Eldena_L16","Eldena_L8")
confidence_intervals=data.frame(Site=0, year=0, VID=0 , lcl=0, ucl=0)


for (Site in Sites){#loop through each site
  Dat=read.csv(paste0("./data/accuracy_data/",Site,"_spring_pseudo.csv"))
  head(Dat)
  # loop through all the years for the chosen site
  print(Site)
  possYear=2021
  print(paste("Available years:",possYear),quote = FALSE)
  
  # STEP 1 - filter data for period between January 1 - May 15    
  Dat$Year=str_sub(Dat$Date_auto,-4) 
  DatCut = Dat %>% 
    dplyr::filter(Year==as.character(possYear))
  Pdates=split.date(as.vector(DatCut$pseudodate), format=c("d","m","y"),
                    sep="/",merge = T)
  DatCut=subset(DatCut, Pdates>=as.numeric(paste(possYear,"0101", sep="")) &
                  Pdates<=as.numeric(paste(possYear,"0515", sep="")))
  head(DatCut)
  tail(DatCut)
  
  # STEP 2 - filter data for night time (3PM-9AM)
  DatCut$Time_auto= as.POSIXct(DatCut$Time_auto,format="%H:%M:%S")
  sunrise=as.POSIXct("09:00:00",format="%H:%M:%S") 
  sunset=as.POSIXct("15:00:00",format="%H:%M:%S") 
  # filter out daytime events
  DatCut=filter(DatCut, !(DatCut$Time_auto>sunrise & DatCut$Time_auto<sunset))
  
  head(DatCut)
  nrow(DatCut)
  #add missing dates (NA)
  DatCut=
    DatCut %>% 
    mutate(pseudodate=as.Date(pseudodate, tryFormats = c("%d/%m/%Y"))) %>% 
    complete(pseudodate =seq.Date(pseudodate[1],pseudodate[nrow(DatCut)], by="day")) 
  nrow(DatCut)
  
  # summary tables of events
  sumPday= DatCut %>% 
    group_by(pseudodate) %>% 
    mutate(total=sum(abs(VideoC), na.rm = T),
           net=sum(VideoC, na.rm = T),
           pos=sum(VideoC[VideoC==1], na.rm = T),
           neg=sum(VideoC[VideoC==-1], na.rm = T)) %>% 
    distinct(pseudodate, .keep_all = T)
  
  
  # calculate emergence period and max estimate
  sumPday$inv=-sumPday$net #method looks for max positive value
  sumPday$inv=ifelse(is.na(sumPday$inv),0,sumPday$inv)
  result=maxsub(sumPday$inv, inds = T)
  
  start=result$inds[1] #index of start date
  end=result$inds[2] #index of end date
  netvalue=result$sum #net between start & end date
  
  #emergence dates
  dates=read.csv("./emergence/LB_estimates_dates.csv")
  
  if(Site=="Eldena_L16"| Site=="Eldena_L8"){
    startdate=dates$start[dates$Site=="Eldena" & dates$year==possYear] #start date
    enddate=dates$end[dates$Site=="Eldena" & dates$year==possYear] #end date
  }else {
    startdate=dates$start[dates$Site==Site & dates$year==possYear] #start date
    enddate=dates$end[dates$Site==Site & dates$year==possYear] #end date
  }
  
  print(paste("Start of emergence:",startdate),quote = FALSE)
  print(paste("End of emergence:",enddate),quote = FALSE)
  print(paste("Estimate:",netvalue),quote = FALSE) #net between start & end date
  
  row_em=c(Site=Site, year=possYear, start=as.character(startdate), 
           end=as.character(enddate), estimate=netvalue)
  # calculate passes 
  
  merged_spring=Dat %>% 
    filter(as.Date(Dat$pseudodate,tryFormats = c("%d/%m/%Y"))>as.Date(startdate,tryFormats = c("%Y-%m-%d")) & 
             as.Date(Dat$pseudodate,tryFormats = c("%d/%m/%Y"))<as.Date(enddate,tryFormats = c("%Y-%m-%d"))) %>% 
    mutate(hour=substr(Time_auto,1,2))
  
  #average passes/NET per hour
  passes_hour=merged_spring %>%
    group_by(pseudodate) %>% 
    summarise(n=sum(abs(VideoC),na.rm = T),
              net=sum(VideoC,na.rm = T)) 
  
  
  total_pass=sum(passes_hour$n)
  print(paste0("Total passes during emergence: ",total_pass),quote = FALSE)
 
  SD=1
  mean_net_error=0
  real_chunks=floor(total_pass/100)
  se=SD/sqrt(real_chunks)
  conf = round((mean_net_error + qt(1 - (0.05 / 2), real_chunks - 1) * se) * real_chunks,0)
 
  
  if(Site=="Anklam"){
    print(paste0("Video estimate (corrected) = ",
                 netvalue+108,'(',netvalue+108-conf-13,' - ',netvalue+108+conf+17,')')
          ,quote = FALSE)
    row=c(Site,possYear,netvalue+108,netvalue+108-conf-13,netvalue+108+conf+17)
  } else if (Site=="Demmin"){
    netvalue=netvalue+5 #missed NET between 02-17 and 02-20
    print(paste0("Video estimate (corrected) = ",
                 netvalue," ± ",conf),quote = FALSE)
    row=c(Site,possYear,netvalue,netvalue-conf,netvalue+conf)
  }else if (Site=="Eldena_L8" | Site=="Eldena_L16"){
    netvalue=netvalue+274 #add estimate of L4
    #2766 passes, em: 01.23 - 05.02, blocked hours=0, 274 (237 - 311)
    #missed passes 259.22, real chunk = 29, pass/max ratio 10.09, SD adj=3.32
    #mean error = 0
    print(paste0("Video estimate (corrected) = ",
                 netvalue," ± ",conf+37),quote = FALSE)
    row=c(Site,possYear,netvalue,netvalue-conf-37,netvalue+conf+37)
  } else{
    print(paste0("Video estimate = ",netvalue," ± ",conf),quote = FALSE)
    row=c(Site,possYear,netvalue,netvalue-conf,netvalue+conf)
   }
  
  print("-------------------------",quote=FALSE)
  
  confidence_intervals=rbind(confidence_intervals,row)
  
} 

write.csv(confidence_intervals[-1,],
          paste0("./accuracy/output/video_CI_IRsites.csv"),
          row.names = F)
```

