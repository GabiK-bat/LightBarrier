---
title: "pipeline"
author: "GabiK"
date: '2022-06-12'
output: html_document
editor_options: 
  chunk_output_type: console
---

#Population size estimation with confidence interval 
Suitable for a chosen year at a site with one light barrier 

RAW LIGHT BARRIER FILES
- save light barrier data to "path" folder from Chirograph software
- use export function "ASCII Tagesdaten (mark Alle Lichtschranken)", save it as space separated txt file
- save curtain data when available to "path2" folder from CorrectNL software
- file names should be 'Sitename.txt')

```{r general_parameters, include=FALSE}
#parameters to be set manually
Site="Friedland"
year=2021

#light barrier name (default LS1 A)
LB="LS1"
LS="A"
#if light barrier is installed at the entrance apply daytime filter (events will be removed between 9AM and 3PM), set to FALSE to switch off filter
Entrance=TRUE

#folder with raw light barrier file (important: file name should be 'Sitename.txt')
path="./data/test_example_for_pipeline/raw_spring_emergence/"
#folder with curtain data when available (important: file name should be 'Sitename.txt')
path2="./data/test_example_for_pipeline/curtain_data/"
#folder where csv files with pseudoday files will automatically be saved
path3="./data/test_example_for_pipeline/pseudo_spring_emergence/"
#folder where to save all other outputs (e.g. emergence plot, estimates)
path4="./data/test_example_for_pipeline/emergence/output/"
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# required packages
library(adagio)
library(tidyverse)
library(scales)
library(lubridate)
library(fitdistrplus)
library(reticulate)
# required scripts
source("./TimeFrame5.R")
source("./smallestsubwithsum.R")
```

```{r functions}
monthly <- function(x) {
        x_range <- range(x, na.rm = TRUE)
        
        date_range <- c(
          floor_date(x_range[1], "month"),
          ceiling_date(x_range[2], "month")
        )
        monthly <- seq(date_range[1], date_range[2], by = "1 month")
        
        monthly
}

# mean net error set to ±1, SD extrapolated based on regression
estimate_with_SD = function(passes,max,mean_pass,blocked_hours=0){
    chunk=floor(passes/100)
    #Regression (ratio of total passes:population size estimate to missed passes)
    #estimated regression slope = 0.83
    regression_estimate_SD=0.83
    missedpasses=0.2*chunk + 1*chunk + chunk*regression_estimate_SD*(passes/max) + blocked_hours*mean_pass
    missed_chunks=round(missedpasses/100,1)
    real_chunks=floor(chunk+missed_chunks)
    print(paste0("Original chunks: ",chunk),quote = FALSE)
    print(paste0("Real chunks: ",real_chunks),quote = FALSE)
    ratio=round(passes/max,2)
    print(paste0("Total passes/population size estimate = ",ratio),quote = FALSE)
    #Regression (ratio of total passes:population size estimate to SD)
    #estimated regression slope = 0.22
    #SD=1 accounts for error based on consecutive LBs in Eldena, Gaussian error prop
    regression_estimate=0.22
    SD=round(sqrt((1*1)+(ratio*regression_estimate)*(ratio*regression_estimate)),2) 
    print(paste0("SD extrapolated = ",SD),quote = FALSE)
    se=SD/sqrt(real_chunks)
    mean_net_error=0
    print("Mean net error set to ±1 ",quote = FALSE)
    lcl = round(((mean_net_error-1) - qt(1 - (0.05 / 2), real_chunks - 1) * se) * real_chunks,0)
    ucl = round(((mean_net_error+1) + qt(1 - (0.05 / 2), real_chunks - 1) * se) * real_chunks,0)
    print(paste0("Population size estimate: ",max," (",max+lcl,"-",max+ucl,")") ,quote = FALSE)
    return(c(max,max+lcl,max+ucl))
}
```

# STEP 1 - pseudoday calculation

```{r Pseudoday_calculation, echo=FALSE}
#pseudoday = a day lasting from 12AM to 12AM 
#run only once, creates csv output files
file=(paste0(path,Site,".txt"))
Dat=read.table(file)
colnames(Dat)=c("Datum", "Uhrzeit", "Type", "LS", "Event")
#head(Dat)
#tail(Dat)
  
print(paste("Calculating pseudodays for",Site,"with",nrow(Dat),"rows!"))

### create PSEUDODAYS that lasts from 12 AM to 12 AM
Dat$EventSec=to.second(as.character(Dat$Uhrzeit))
Dat$Datum=reformat.date(as.vector(Dat$Datum),to.sep="-", to.format=c("y","m","d"))
Dat$Datum=as.Date(Dat$Datum)
  
#head(Dat)
Dat$pseudodate=ifelse(Dat$EventSec>43200,as.character(Dat$Datum),
                        as.character(Dat$Datum-1))
Dat$EventC = as.factor(Dat$Event)
levels(Dat$EventC) = c("-1","1")
Dat$EventC = as.numeric(as.vector(Dat$EventC))
Dat$Year=format(as.Date(Dat$Datum, format="%Y-%m-%d"),"%Y")
#head(Dat)
  
#save output as csv file
write.csv(Dat, paste0(path3,Site,"_pseudo.csv"), row.names = F)

```

# STEP 2 - outlier detection & estimation

```{r parameters}
#date range for detecting outliers, default: Jan 1 - May 15
startdate=as.Date(paste0(year,"-01-01"))
enddate=as.Date(paste0(year,"-05-15"))
```

```{r outlier_detection}
d=read.csv(paste0(path2,Site,".txt"), header=TRUE, sep=";")
#head(d)
d$Datum=as.Date(d$Datum, tryFormats=c("%d.%m.%Y"))

### create PSEUDODAYS - 12 AM to 12 AM
d$EventSec=to.second(as.character(d$Uhrzeit))
d$pseudodate=ifelse(d$EventSec>43200,as.character(d$Datum),
                      as.character(d$Datum-1))
d$pseudodate=as.Date(d$pseudodate)
#head(d)

df=d %>% 
  filter(pseudodate > startdate & pseudodate < enddate) %>% 
  filter(Event== paste(LB,"Ausflug") |
           Event== paste(LB,"Einflug") |
           Event== paste(LB, "EStatus 0")|
           Event== paste(LB, "EStatus 1")|
           Event== paste(LB, "EStatus 2")|
           Event== paste(LB, "EStatus 3")) %>% 
  dplyr::select(pseudodate, Uhrzeit,Event) %>% 
  group_by(pseudodate) %>% 
  count(group=Event== paste(LB,"Ausflug") |
          Event== paste(LB,"Einflug")) %>% 
  spread(value=n, key=group) %>% 
  rename("curtain"=`FALSE`, "passes"=`TRUE`) %>% 
  mutate(ratio=curtain/passes, na.rm=T)

#curtain registrations over time
p=df %>% 
  ggplot(aes(x=pseudodate, y=curtain))+
  geom_line() +
  labs(y='curtain registrations', 
       x='')+
  ggtitle(paste(Site,year))+
  theme_bw()+
  scale_y_continuous(labels = comma_format())+
  scale_x_date(breaks="2 weeks", date_labels = "%b %d")+
  theme(plot.title = element_text(hjust = 0.5))
p
print("Check plot for outliers!")
p+# potential outlier night
  geom_vline(xintercept = as.Date("2021-03-27"), col="red")+
  geom_vline(xintercept = as.Date("2021-03-29"), col="red")
```

```{r gamma_distribution}
#gamma distribution fitted to curtain registrations
fit.gamma <- fitdist(df$curtain/10, distr = "gamma", method = "mle")
summary(fit.gamma)
plot(fit.gamma)
print("Check plot for outliers!")
```

```{r outlier_parameters}
#if outlier night was detected visually, specify details here in order to estimate total and net passes of the outlier night based on the average of the  preceding and following 3 nights
outlier=TRUE #set to TRUE if outlier was detected, otherwise FALSE
outlier_night="2021-03-28" #set pseudodate of outlier night
```

# STEP 3 - creating files to separate the emergence phase from early summer activity 

```{r parameters}
#folder where files will be saved 
path5="./data/test_example_for_pipeline/emergence/"
```

```{r creating_data_files}
#run only once to generate text files that will be used in Python
#output: data tables for each year between Jan 1 and July 31 with number of passes/night
Dat=read.csv(paste0(path3,Site,"_pseudo.csv"))
#head(Dat)
possYear=year
  
DatCut=
  Dat %>% 
  dplyr::filter(Year==as.character(possYear))
Pdates=split.date(as.vector(DatCut$pseudodate), format=c("y","m","d"),
                  sep="-",merge = T)
#head(DatCut)
#tail(DatCut)
    
DatCut$Uhrzeit= as.POSIXct(DatCut$Uhrzeit,format="%H:%M:%S")
sunrise=as.POSIXct("09:00:00",format="%H:%M:%S") 
sunset=as.POSIXct("15:00:00",format="%H:%M:%S") 
    
# filter out daytime events if light barrier is installed directly at the entrance
if (Entrance==TRUE){
  DatCut=filter(DatCut, !(DatCut$Uhrzeit>sunrise & DatCut$Uhrzeit<sunset))
}

#add missing dates 
DatCut=
    DatCut %>% 
    mutate(pseudodate=as.Date(pseudodate)) %>% 
    complete(pseudodate =seq.Date(pseudodate[1],
                                  pseudodate[nrow(DatCut)], 
                                  by="day")) 
DatCut$EventC=as.numeric(as.character(DatCut$EventC))
    
#summary tables of events
sumPday=DatCut %>% 
      group_by(pseudodate) %>% 
      mutate(total=sum(abs(EventC), na.rm = T),
             net=sum(EventC, na.rm = T),
             pos=sum(EventC[EventC==1], na.rm = T),
             neg=sum(EventC[EventC==-1], na.rm = T)) %>% 
      distinct(pseudodate, .keep_all = T)
   
final=sumPday %>%
        ungroup() %>%
        dplyr::select(total,net)
    
#save output as txt file
write.table(final, paste0(path5,Site,"_",possYear,"_emergence_split.txt"),
                row.names = T, quote=F, col.names = F)
   
```

#STEP 4 - separate the emergence phase from early summer activity 
IMPORTANT: required to install Python and following packages

```{r install_Python_packages}
#py_install("lmfit")
#py_install("matplotlib")
```

```{r set_workdir}
workdir=getwd()
workdir=str_split(workdir,pattern="/")
workdir=paste0(workdir[[1]][1],"/",workdir[[1]][2],"/")
print(paste("Current working directory:",workdir))
#IMPORTANT: manually add working directory in the chunk below as "workdir"
```

```{python pipeline}
import lmfit as fit
import numpy as np
import os
from glob import glob
import matplotlib.pyplot as plt
from scipy.signal import find_peaks
from scipy.signal import savgol_filter

def fit_func(x, intensity1, shift1, std1,intensity2, shift2, std2 ):
    return intensity1*np.exp(-(1/2)*(x-shift1)**2/std1**2) + intensity2*np.exp(-(1/2)*(x-shift2)**2/std2**2)

#IMPORTANT: manually change working directory here
workdir="D:/CountingDark_R/"

path=(workdir+"/data/test_example_for_pipeline/emergence")
print(path)
os.chdir(path) #sets the current working directory to path
files=[]
for file in glob("*.txt"):
    files.append(file) #creates a list of txt files in working dir
print(files)

fh = open(path+'/output/earlysummer_start_days.txt', 'w') #write text file with result

for cfile in files:
    Site=cfile.split("_")[0]
    print(Site)
    year=cfile.split("_")[1].split(".")[0]
#    print(Site+year)
#    print(cfile)
    try:
        data = np.loadtxt(cfile)
    except:
        print("could not load", cfile)
        continue
    #plt.plot(data[:,1])
    
    x=data[:,0]
    y=data[:,1]
    
    plt.close('all')
    
    fig, ax = plt.subplots()
    plt.title(Site + " " + year)
    plt.xlabel("days since January 1")
    plt.ylabel("number of passes / night")
    ax.plot(x,y, 'ko', ms=2)
    y = savgol_filter(y, 51, 2)
    #print(y)
    print("file saved!")
    pr=np.max(y[0:200])*0.1 #ratio should be revised
    peaks,_ = find_peaks(y,prominence=pr,distance=10)
    ax.plot(x,y, '-', label = 'smoothened data')
#    print(peaks)
    if len(peaks) < 2:
        print(cfile, "less than 2 peaks found")
        plt.tight_layout()
        plt.savefig(path+'/output/'+Site+'_'+year+'.png')
        fh.write( Site + '\t'+  year + '\t'+ 'NA' +'\n')
        continue
#    for i in peaks:
#        #print(i)
#        if i <200:
#            ax.axvline(i, ls = '--') #plot dashed lines where peaks are
    if peaks[1]>200:
        print('no early summer activity', cfile)
        fh.write( Site + '\t'+  year + '\t'+ 'NA' +'\n')
        continue
    

    gmodel = fit.Model(fit_func)
    parameters = fit.Parameters()
    parameters.add('intensity1', value = 2000, min = 1, max = 3000)
    parameters.add('shift1', value = peaks[0], min = peaks[0]-4, max = peaks[0]+4)
    parameters.add('std1', value = 11, min = 5, max = 21)
    
    parameters.add('intensity2', value = 2000, min = 1, max = 3000)
    parameters.add('shift2', value = peaks[1],min = peaks[1]-4, max = peaks[1]+4)
    parameters.add('std2', value = 11, min = 5, max = 21)
    
    #fitres = gmodel.fit(y[0:120], parameters, x = x[0:120])
    fitres = gmodel.fit(y[0:200], parameters, x = x[0:200])
    I = fitres.best_values['intensity1']
    s = fitres.best_values['shift1']
    d = fitres.best_values['std1']
    
    I2 = fitres.best_values['intensity2']
    s2 = fitres.best_values['shift2']
    d2 = fitres.best_values['std2']
    print(I,s,d, I2, s2, d2)

    
    ax.plot(x,I*np.exp(-(1/2)*(x-s)**2/d**2),label = 'emergence',color='orange')
    ax.plot(x,I2*np.exp(-(1/2)*(x-s2)**2/d2**2), label = 'early summer',color='green')
    ax.legend()
    
    def solve_gaussian_crossing(a1,a2,s1,s2,x1,x2):
        a = s2**2 -s1**2
        b = 2*(x2*s1**2-x1*s2**2)
        c = s2**2*x1**2-s1**2*x2**2  -2*s1**2*s2**2*(np.log(a1)-np.log(a2))
        D = b**2-4*a*c
        if D < 0:
            print('no solution')
            return []
        if D == 0:
            print('only one solution')
            return -b/(2*a)
        sol1 = (-b + np.sqrt(D))/(2*a)
        sol2 = (-b - np.sqrt(D))/(2*a)
        #print(sol1)
        #print(sol2)
        return np.array([sol1, sol2])

    result=solve_gaussian_crossing(I,I2,d,d2,s,s2)
    print(result)
    
    ind = np.where((result>0) & (result<200)) #arbitrary, should be revised
    print(result[ind][0])
    ax.axvline(result[ind][0], ls = '--')

    if len(ind) == 0:
        print(cfile, "no solutions between 0 and 200")
        fh.write( Site + '\t'+  year + '\t'+ 'NA' +'\n')
        continue
    if len(ind)>1:
        print(cfile, "more than one solution between 0 and 200")
        print(result)
    #continue
    try:
        date="{:.0f}".format(result[ind][0])
    except:
        print(cfile, ' date string exception')
        fh.write( Site + '\t'+  year + '\t'+ 'NA' +'\n')
        continue
    
    plt.tight_layout()
    plt.savefig(path+'/output/'+Site+'_'+year+'_emergence_split.png')
    
    fh.write( Site + '\t'+  year + '\t'+ date +'\n')
fh.close()
```

```{r set_workdir}
setwd(workdir)
print(paste("Current working directory:",getwd()))
```

#STEP 5 - emergence phase estimation
```{r emergence_estimation}
conf_ints=data.frame(Site=0, year=0, lcl=0 , max=0,ucl=0,SD=0, passes=0)
emergence_dates=data.frame(Site=0, year=0, start=0 , end=0, estimate=0,
                           total_passes=0,
                           earlysummer_passes=0,
                           autumn_passes=0)

Dat=read.csv(paste0(path3,Site,"_pseudo.csv"))
      
    
print(paste("Emergence estimation for",Site,year))
possYear=as.numeric(year)
DatCut = Dat %>% 
    dplyr::filter(Year==as.numeric(possYear)|
                      Year==as.numeric(possYear)-1)
Pdates=split.date(as.vector(DatCut$pseudodate), format=c("y","m","d"),
                      sep="-",merge = T)
    
#calculate number of passing during autumn (defined here as Jul 1 - Jan 1)
autumn=subset(DatCut, Pdates>=as.numeric(paste(possYear-1,"0701", sep="")) &
                    Pdates<=as.numeric(paste(possYear,"0101", sep="")))
    
#DAYTIME filter (filter out events between 9AM and 3PM)
autumn$Uhrzeit= as.POSIXct(autumn$Uhrzeit,format="%H:%M:%S")
DatCut$Uhrzeit= as.POSIXct(DatCut$Uhrzeit,format="%H:%M:%S")
sunrise=as.POSIXct("09:00:00",format="%H:%M:%S") 
sunset=as.POSIXct("15:00:00",format="%H:%M:%S") 
    
# filter out daytime events if light barrier is at the entrance (Entrance=TRUE)
if (Entrance==TRUE){ 
  autumn=filter(autumn, !(autumn$Uhrzeit>sunrise & autumn$Uhrzeit<sunset))
  DatCut=filter(DatCut, !(DatCut$Uhrzeit>sunrise & DatCut$Uhrzeit<sunset))
}
    
#add missing dates (when no light barrier pass was registered) in autumn
autumn=
    autumn %>% 
    mutate(pseudodate=as.Date(pseudodate)) %>% 
    complete(pseudodate =seq.Date(pseudodate[1],pseudodate[nrow(autumn)], by="day")) 
    
#summary of all light barrier events in autumn
sumPdayF_autumn= autumn %>% 
    group_by(pseudodate) %>% 
    mutate(total=sum(abs(EventC), na.rm = T),
           net=sum(EventC, na.rm = T),
           pos=sum(EventC[EventC==1], na.rm = T),
           neg=sum(EventC[EventC==-1], na.rm = T)) %>% 
    distinct(pseudodate, .keep_all = T)
autumn_passes=sum(sumPdayF_autumn$total)
    
#set range for plot (here July 1 to July 1)
DatCut$pseudodate=as.Date(DatCut$pseudodate)
DatCut=subset(DatCut, Pdates>=as.numeric(paste(possYear-1,"0701", sep="")) &
                    Pdates<=as.numeric(paste(possYear,"0701", sep="")))
    
#add missing dates between July 1 to July 1
atCut=
  DatCut %>% 
  mutate(pseudodate=as.Date(pseudodate)) %>% 
  complete(pseudodate =seq.Date(pseudodate[1],as.Date(paste0(possYear,"-06-30")), by="day")) 
    
# estimate passes and net for if an outlier night was detected
if (outlier==TRUE){
    
 #summary of all light barrier events between July 1 to July 1
  sumPdayF= DatCut %>% 
      group_by(pseudodate) %>% 
      mutate(total=sum(abs(EventC), na.rm = T),
            net=sum(EventC, na.rm = T),
             pos=sum(EventC[EventC==1], na.rm = T),
             neg=sum(EventC[EventC==-1], na.rm = T)) %>% 
      distinct(pseudodate, .keep_all = T)
    
  df=sumPdayF %>% 
        dplyr::select(pseudodate,total,net,pos,neg)
    
  #outlier night
  ind=which(df$pseudodate==as.Date(outlier_night))
      
  df$total_est=df$total
  df$net_est=df$net
  df$pos_est=df$pos
  df$neg_est=df$neg
    
  #estimate total and net passes on outlier night
  df$total_est[ind]=round((df$total[ind-1]+ df$total[ind-2]+ df$total[ind-3]+
                              df$total[ind+1] + df$total[ind+2] +   df$total[ind+3])/6)
        
  df$net_est[ind]=round((df$net[ind-1]+ df$net[ind-2]+ df$net[ind-3]+
                           df$net[ind+1] + df$net[ind+2] +   df$net[ind+3])/6)
        
  df$pos_est[ind]=round((df$pos[ind-1]+ df$pos[ind-2]+ df$pos[ind-3]+
                                 df$pos[ind+1] + df$pos[ind+2] +   df$pos[ind+3])/6)
        
  df$neg_est[ind]=round((df$neg[ind-1]+ df$neg[ind-2]+ df$neg[ind-3]+
                                 df$neg[ind+1] + df$neg[ind+2] +   df$neg[ind+3])/6)
        
  sumPdayF=df %>% 
          dplyr::select(pseudodate, total_est, net_est, neg_est, pos_est) %>% 
          rename(total=total_est, net=net_est, neg=neg_est, pos=pos_est)
      
    
}else{
       
    #if there was no outlier night detected
  sumPdayF= DatCut %>% 
      group_by(pseudodate) %>% 
      mutate(total=sum(abs(EventC), na.rm = T),
            net=sum(EventC, na.rm = T),
             pos=sum(EventC[EventC==1], na.rm = T),
             neg=sum(EventC[EventC==-1], na.rm = T)) %>% 
      distinct(pseudodate, .keep_all = T)
}
    

#set search window for emergence phase
#start is default Jan 1, end is the start of early summer activity swarming (from Python output)
may_peak=read.table(paste0(path5,"/output/earlysummer_start_days.txt"), header=F, sep="\t")
colnames(may_peak)=c("Site","year","day")
    
#set start to default Jan 1
sumPday=subset(sumPdayF, pseudodate>=as.Date(paste(possYear,"-01-01", sep=""))) 
    
day=may_peak$day[may_peak$Site==Site & may_peak$year==possYear]

#if no early summer activity, default May 15
if(is.na(day)){
  day=136
}

#cut at the start of early summer activity 
sumPday_may=sumPday[1:day,]
    
#early summer activity data to calculate passes
early_summer_data=sumPday[day:nrow(sumPday),]
early_summer_data=
    early_summer_data %>% 
    filter(pseudodate<as.Date(paste0(possYear,"-07-02")))
early_summer_passes=sum(early_summer_data$total)
    
# calculate emergence phase based on max net values (population size estimate)
sumPday_may$inv=-sumPday_may$net #method looks for max positive value
sumPday_may$inv=ifelse(is.na(sumPday_may$inv),0,sumPday_may$inv)
result=maxsub(sumPday_may$inv, inds = T)
    
start=result$inds[1] #index of start date
end=result$inds[2] #index of end date
netvalue=result$sum #net between start & end date
    
startdate=sumPday_may$pseudodate[start] #start date
startdate
enddate=sumPday_may$pseudodate[end] #end date
enddate
netvalue #net between start & end date
    
#subset data for emergence phase
Pdates2=split.date(as.character(sumPday$pseudodate), 
                       format=c("y","m","d"),
                       sep="-",merge = T)
startdateID=split.date(as.character(startdate), 
                       format=c("y","m","d"),
                       sep="-",merge = T)
enddateID=split.date(as.character(enddate), 
                     format=c("y","m","d"),
                     sep="-",merge = T)
sumPday2=subset(sumPday, Pdates2>=as.numeric(startdateID) &
                  Pdates2<=as.numeric(enddateID) )
  #saved dates and passes in a table
row_em=c(Site=Site, year=possYear, start=as.character(startdate), 
         end=as.character(enddate), estimate=netvalue,
         total_passes=sum(sumPday2$total),
         earlysummer_passes=early_summer_passes,
         autumn_passes=autumn_passes)

emergence_dates=rbind(emergence_dates,row_em)

###### EMERGENCE PLOT
sumPday$type=sumPday$net>0
may_start_date=sumPday$pseudodate[day]

emergence_df=
  sumPday %>%
  dplyr::select(pseudodate,pos,neg) %>%
  gather("direction","passes",-pseudodate)
minact=min(emergence_df$passes)

#emergence plot
sumPdayF= DatCut %>% 
    group_by(pseudodate) %>% 
    mutate(total=sum(abs(EventC), na.rm = T),
           net=sum(EventC, na.rm = T),
           pos=sum(EventC[EventC==1], na.rm = T),
           neg=sum(EventC[EventC==-1], na.rm = T)) %>% 
    distinct(pseudodate, .keep_all = T)
sumPdayF$type=sumPdayF$net>0
      
  #emergence plot 
emergence=emergence_df %>%
  ggplot(aes(pseudodate,passes))+
  #start-end of emergence phase
  annotate("rect",xmin=startdate, xmax=enddate,
           ymin=minact*1.20,ymax=minact*1.05,alpha=0.7,fill="#D1E5F0")+
  #start of early summer
  geom_vline(xintercept = may_start_date,col="grey50",size=0.5, linetype="dashed")+
  geom_vline(xintercept = as.Date(paste0(possYear,"-01-01")),col="grey50",size=0.5, linetype="dashed")+
  geom_col(fill="grey70",col="grey40",size=0.2)+
  scale_fill_manual(values=c("#994ba9","#b77ac4"))+
  geom_col(data=sumPday,aes(pseudodate,net,fill=type))+
  scale_x_date(date_labels = "%d %b",
               breaks="3 weeks")+
  labs(x="",y="number of passes", title = paste(Site,year))+
  theme_bw()+
  theme(panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    axis.line = element_line(colour = "black"))+
  theme(legend.position = "none")+
  scale_y_continuous(breaks=pretty_breaks(n=6))
dev.off()
emergence
ggsave(paste0(path4,Site,"_",possYear,".png"),
       width = 18, height = 10, dpi = 800, units = "cm", device='png')

   
write.csv(emergence_dates[-1,], 
          paste0(path4,"LB_estimates_dates.csv"),
          row.names = F)

```

```{r blocked_periods}
blocked_periods=data.frame(blocked_minute=0)
blocked_hours_df=data.frame(Site=0,blocked_hours=0)
#calculate blocked periods
dat=read.csv(paste0(path2,Site,".txt"), sep=";")
status=dat %>% 
  dplyr::select(Datum,Uhrzeit,Event) %>% 
  filter(grepl('Status', Event)) %>% 
  mutate(datetime=paste(as.character(Datum),as.character(Uhrzeit)))
status$datetime2=as.POSIXct(status$datetime,format="%d.%m.%Y %H:%M:%S", tz="GMT")
status$Datum=as.Date(status$Datum, tryFormats = c("%d.%m.%Y"))

#emergence dates and population size estimates
emergence_start=startdate
emergence_end=enddate
   
stat_filt=
    status %>% 
    filter(as.Date(status$Datum)>as.Date(emergence_start) & 
             as.Date(status$Datum)<as.Date(emergence_end)) %>% 
    filter(grepl(LB,Event))
  
  nrow(stat_filt)
  zeros=which(stat_filt$Event==paste0(LB," EStatus 0")) #indices of Status 0
  threshold=1 #minutes, set time between Status 1/2/3 (that is after a 0) and next 0
  
  for (i in zeros[-length(zeros)]) {    
    if (stat_filt$Event[i+1]!=paste0(LB," EStatus 0")) {  # check if next event is Status 1/2/3 
      #print(i)
      first_datetime=stat_filt$datetime2[i+1] # date time of the Status 1/2/3 event
      which(zeros==i) #index of current 0
      which(zeros==i)+ 1#index of next 0
      zeros[which(zeros==i)+ 1] #row of next 0
      last_datetime=stat_filt$datetime2[zeros[which(zeros==i)+ 1]] #date time of next 0
      time_diff=difftime(last_datetime,first_datetime, units="mins")
      if (as.numeric(time_diff) > threshold) {
        #print(paste("LB blocked from",first_datetime,"to",last_datetime))
        minutes=seq(first_datetime,last_datetime, by='min')
        minutes=format(minutes,"%Y-%m-%d %H:%M:%S")
        for (m in 1:length(minutes)){
          if(format(strptime(minutes[m],"%Y-%m-%d %H:%M:%S"),'%H:%M:%S')<"09:00:00" |
             format(strptime(minutes[m],"%Y-%m-%d %H:%M:%S"),'%H:%M:%S')>"15:00:00"){
            row=c(as.character(minutes[m]))
            blocked_periods=rbind(blocked_periods,as.character(row))  
          }
        }
      }
    }
  }
      
blocked_periods=blocked_periods[-1,]
length(unique(blocked_periods))
round(length(unique(blocked_periods))/60,0)
row2=c(Site, round(length(unique(blocked_periods))/60,0))
blocked_hours_df=rbind(blocked_hours_df,row2)

Dat=read.csv(paste0(path3,Site,"_pseudo.csv"))
str(Dat)
head(Dat)
      
Dat=Dat %>% 
  mutate(Uhrzeit = as.POSIXct(Uhrzeit, format = "%H:%M:%S"),
        hour = sprintf("%02d", hour(Uhrzeit)))

merged_spring=
  Dat %>% 
   mutate(Uhrzeit = as.POSIXct(Uhrzeit, format = "%H:%M:%S"),
          hour = strftime(Uhrzeit, format="%H")) %>% 
   filter(as.Date(Dat$pseudodate)>as.Date(emergence_start) & 
          as.Date(Dat$pseudodate)<as.Date(emergence_end))

merged_spring$hour=as.numeric(merged_spring$hour)
merged_spring$pseudodate=ymd(merged_spring$pseudodate)


#average passes and net per hour
passes_hour=merged_spring %>%
  filter(hour>15 | hour<9) %>% #daytime filter
  group_by(pseudodate,hour) %>% 
  summarise(n=sum(abs(EventC)),
            net=sum(EventC)) %>%
  ungroup() %>% 
  complete(pseudodate=seq(min(pseudodate),max(pseudodate),by='day'), 
                               fill = list(n= 0, hour=0, net=0)) %>%
  group_by(pseudodate) %>% 
  complete(hour=c(seq(15,23),seq(0,9)),
           fill = list(n= 0, net=0)) 

total_pass=sum(passes_hour$n)
print(paste0("Total passes during emergence after excluding outlier night: ",total_pass),quote = FALSE)
mean_pass=round(mean(passes_hour$n),2)
print(paste0("Average passes per hour during emergence: ",mean_pass),quote = FALSE)
net_pass=round(mean(passes_hour$net),2)
print(paste0("Average net per hour during emergence: ",net_pass),quote = FALSE)

#calculate confidence interval for NET passes/hour
sd=sd(passes_hour$net)
n_chunk=length(passes_hour$net)
se=sd / sqrt(n_chunk)
ucl = net_pass - qt(1 - (0.05 / 2), n_chunk - 1) * se
ucl
print(paste0("Average NET per hour UCL: ",round(ucl,2)),quote = FALSE)

lcl = net_pass + qt(1 - (0.05 / 2), n_chunk - 1) * se
lcl
print(paste0("Average NET per hour LCL: ",round(lcl,2)),quote = FALSE)

#Site-specific blocked hours   
blocked_hours=as.numeric(blocked_hours_df$blocked_hours[blocked_hours_df$Site==Site])
print(paste0("Blocked hours: ",blocked_hours," hrs"),quote = FALSE)

correction_lower=round(blocked_hours*lcl,0)
print(paste("Correct lcl due to blocked hours:",correction_lower),quote = FALSE)
correction_upper=round(blocked_hours*ucl,0)
print(paste("Correct ucl due to blocked hours:",correction_upper),quote = FALSE)
 
```

#STEP 6 - confidence interval
```{r confidence_interval}
confidence_intervals=data.frame(Site=0, year=0, LB=0 , lcl=0, ucl=0)

a=estimate_with_SD(total_pass, netvalue,mean_pass,blocked_hours) 
    
row=c(Site,possYear,a[1],
      a[2]+abs(correction_lower),
      a[3]+abs(correction_upper))
    #print(row)
    #print("------------------------------------")
confidence_intervals=rbind(confidence_intervals,row)
print(paste0("Population size estimate in ",Site," ",year," is ", a[1]," (",
            a[2],"-",a[3],")"))

write.csv(confidence_intervals[-1,],
          paste0(path4,"confidence_intervals.csv"),
          row.names = F)
```

